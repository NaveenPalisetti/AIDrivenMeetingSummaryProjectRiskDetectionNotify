{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8344111b",
   "metadata": {},
   "source": [
    "# meeting_mcp Colab / ngrok helper\n",
    "\n",
    "This notebook prepares a Colab environment to run the `meeting_mcp` FastAPI backend and Streamlit UI, exposes them via ngrok, and copies local model files from Google Drive into the repo for faster local loading.\n",
    "\n",
    "Run cells in order. Update paths and tokens where prompted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0feed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Install Python dependencies. Uncomment to run in Colab if needed.\n",
    "# NOTE: installing all requirements may take several minutes.\n",
    "# Install from the repo requirements (adjust path if you cloned into /content)\n",
    "# !pip install -r /content/AIDrivenMeetingSummaryProjectRiskDetection/requirements.txt --quiet\n",
    "# Common useful packages (uncomment as needed):\n",
    "# !pip install streamlit pyngrok --quiet\n",
    "# !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118 --quiet\n",
    "# !pip install bitsandbytes --quiet\n",
    "# !pip install uvicorn --quiet\n",
    "print('Skip installs if your environment already has the required packages.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository into /content in Colab if not already present, and set REPO_ROOT\n",
    "import os, subprocess, pathlib\n",
    "repo_dir = '/content/AIDrivenMeetingSummaryProjectRiskDetection'\n",
    "if not pathlib.Path(repo_dir).exists():\n",
    "    print('Cloning repository to', repo_dir)\n",
    "    try:\n",
    "        subprocess.check_call(['git','clone','https://github.com/NaveenPalisetti/AIDrivenMeetingSummaryProjectRiskDetection.git', repo_dir])\n",
    "    except Exception as e:\n",
    "        print('git clone failed:', e)\n",
    "else:\n",
    "    print('Repository already exists at', repo_dir)\n",
    "os.environ['REPO_ROOT'] = repo_dir\n",
    "print('Set REPO_ROOT =', os.environ['REPO_ROOT'])\n",
    "# Change working directory for the notebook runtime to the repo root\n",
    "try:\n",
    "    os.chdir(repo_dir)\n",
    "    print('Changed CWD to', repo_dir)\n",
    "except Exception as e:\n",
    "    print('Failed to chdir to repo root:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements from the cloned repository (uncomment to run).\n",
    "import os\n",
    "repo = os.environ.get('REPO_ROOT', '/content/AIDrivenMeetingSummaryProjectRiskDetection')\n",
    "print('Using repo:', repo)\n",
    "# Uncomment the following lines to install dependencies in Colab\n",
    "# !pip install -r $repo/requirements.txt\n",
    "# Install package in editable mode during development\n",
    "# !pip install -e $repo\n",
    "# Heavy / GPU packages (uncomment if you need GPU support):\n",
    "# !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118 --quiet\n",
    "# !pip install bitsandbytes --quiet\n",
    "# !pip install streamlit pyngrok uvicorn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install minimal dependencies and optionally copy Mistral model from Drive to /content for faster loading.\n",
    "# Uncomment the pip line when running in Colab (it may take several minutes).\n",
    "# !pip install -r /content/AIDrivenMeetingSummaryProjectRiskDetection/requirements.txt --quiet\n",
    "import shutil, os, pathlib\n",
    "# Optional: copy Mistral model from Google Drive to local disk (adjust source path if needed)\n",
    "src = '/content/drive/MyDrive/Dissertation/Project/models/mistral-7B-Instruct-v0.2'\n",
    "dst = '/content/mistral-7B-Instruct-v0.2'\n",
    "if os.path.exists(src):\n",
    "    if not os.path.exists(dst):\n",
    "        print('Copying Mistral model from Drive to local disk...')\n",
    "        try:\n",
    "            shutil.copytree(src, dst)\n",
    "            print('Copied Mistral model to', dst)\n",
    "        except Exception as e:\n",
    "            print('Failed to copy Mistral model:', e)\n",
    "    else:\n",
    "        print('Local copy of Mistral model already exists at', dst)\n",
    "else:\n",
    "    print('Source Mistral model not found at', src, '— ensure Drive is mounted and path is correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c308d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (only required in Colab) and set model paths.\n",
    "import os\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Mounted Google Drive at /content/drive')\n",
    "except Exception:\n",
    "    print('google.colab not available — ensure models are accessible locally (not in Drive).')\n",
    "\n",
    "# Default Drive paths used previously in this project — update if your Drive uses different paths\n",
    "os.environ.setdefault('BART_MODEL_PATH', '/content/drive/MyDrive/Dissertation/Project/models/local_bart_large_cnn_finetuned')\n",
    "os.environ.setdefault('MISTRAL_MODEL_PATH', '/content/drive/MyDrive/Dissertation/Project/models/mistral-7B-Instruct-v0.2')\n",
    "print('BART_MODEL_PATH =', os.environ.get('BART_MODEL_PATH'))\n",
    "print('MISTRAL_MODEL_PATH =', os.environ.get('MISTRAL_MODEL_PATH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2353a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements from the repo if you prefer the workspace copy (uncomment to run).\n",
    "# Adjust the path to your repo location if different.\n",
    "# !pip install -r /content/drive/MyDrive/Dissertation/Project/requirements.txt --quiet\n",
    "print('If you need dependencies installed, uncomment the pip command in this cell and run it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e5005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy model directories from Drive into local ./models/ for faster local loading.\n",
    "import os, shutil, pathlib\n",
    "dst_root = pathlib.Path('models')\n",
    "dst_root.mkdir(exist_ok=True)\n",
    "# Copy BART model if present\n",
    "bart_src = os.environ.get('BART_MODEL_PATH')\n",
    "bart_dst = dst_root / 'local_bart_large_cnn_finetuned'\n",
    "if bart_src and os.path.exists(bart_src):\n",
    "    try:\n",
    "        if bart_dst.exists():\n",
    "            print(f'BART destination {bart_dst} exists — skipping copy')\n",
    "        else:\n",
    "            print(f'Copying BART model from {bart_src} to {bart_dst} ...')\n",
    "            shutil.copytree(bart_src, bart_dst)\n",
    "            os.environ['BART_MODEL_PATH'] = str(bart_dst)\n",
    "            print('Copied BART model and updated BART_MODEL_PATH')\n",
    "    except Exception as e:\n",
    "        print('Failed to copy BART model:', e)\n",
    "else:\n",
    "    print('BART_MODEL_PATH not set or source missing — skipping BART copy')\n",
    "\n",
    "# Copy Mistral model if present\n",
    "mistral_src = os.environ.get('MISTRAL_MODEL_PATH')\n",
    "mistral_dst = dst_root / 'mistral-7B-Instruct-v0.2'\n",
    "if mistral_src and os.path.exists(mistral_src):\n",
    "    try:\n",
    "        if mistral_dst.exists():\n",
    "            print(f'Mistral destination {mistral_dst} exists — skipping copy')\n",
    "        else:\n",
    "            print(f'Copying Mistral model from {mistral_src} to {mistral_dst} ...')\n",
    "            shutil.copytree(mistral_src, mistral_dst)\n",
    "            os.environ['MISTRAL_MODEL_PATH'] = str(mistral_dst)\n",
    "            print('Copied Mistral model and updated MISTRAL_MODEL_PATH')\n",
    "    except Exception as e:\n",
    "        print('Failed to copy Mistral model:', e)\n",
    "else:\n",
    "    print('MISTRAL_MODEL_PATH not set or source missing — skipping Mistral copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ngrok auth token and MCP_API_KEY (optional).\n",
    "import os\n",
    "if not os.environ.get('NGROK_AUTH_TOKEN'):\n",
    "    try:\n",
    "        v = input('Enter NGROK_AUTH_TOKEN (leave blank to skip): ').strip()\n",
    "        if v:\n",
    "            os.environ['NGROK_AUTH_TOKEN'] = v\n",
    "    except Exception:\n",
    "        pass\n",
    "if not os.environ.get('MCP_API_KEY'):\n",
    "    try:\n",
    "        v = input('Enter MCP_API_KEY to protect the HTTP API (optional): ').strip()\n",
    "        if v:\n",
    "            os.environ['MCP_API_KEY'] = v\n",
    "    except Exception:\n",
    "        pass\n",
    "print('NGROK_AUTH_TOKEN set:', bool(os.environ.get('NGROK_AUTH_TOKEN')) )\n",
    "print('MCP_API_KEY set:', bool(os.environ.get('MCP_API_KEY')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8484636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start FastAPI (uvicorn) in background and capture PID.\n",
    "import subprocess, time, os\n",
    "from pathlib import Path\n",
    "# Prefer an explicit REPO_ROOT or GITHUB_WORKSPACE if set (useful after git clone)\n",
    "repo_root = Path(os.getenv('REPO_ROOT') or os.getenv('GITHUB_WORKSPACE') or Path.cwd())\n",
    "print('Using repo_root =', repo_root)\n",
    "try:\n",
    "    os.chdir(repo_root)\n",
    "except Exception as e:\n",
    "    print('Failed to chdir to repo_root:', e)\n",
    "UVICORN_CMD = ['uvicorn','meeting_mcp.server.mcp_api:app','--host','127.0.0.1','--port','8000','--reload']\n",
    "logf = open('uvicorn_meeting_mcp.log','a')\n",
    "try:\n",
    "    proc = subprocess.Popen(UVICORN_CMD, stdout=logf, stderr=logf)\n",
    "    print('uvicorn started, pid=', proc.pid)\n",
    "    (Path('uvicorn_meeting_mcp.pid')).write_text(str(proc.pid))\n",
    "except Exception as e:\n",
    "    print('Failed to start uvicorn:', e)\n",
    "time.sleep(3)\n",
    "print('Waiting for FastAPI to warm up...')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Streamlit UI in background and create ngrok tunnels for backend and UI.\n",
    "from pyngrok import ngrok, conf\n",
    "import os, subprocess, time\n",
    "from pathlib import Path\n",
    "if os.environ.get('NGROK_AUTH_TOKEN'):\n",
    "    conf.get_default().auth_token = os.environ.get('NGROK_AUTH_TOKEN')\n",
    "# Start Streamlit app (use the meeting_mcp Streamlit client)\n",
    "ST_CMD = ['streamlit','run','meeting_mcp/ui/streamlit_agent_client.py','--server.port','8501']\n",
    "try:\n",
    "    st_proc = subprocess.Popen(ST_CMD, stdout=open('streamlit_meeting_mcp.log','a'), stderr=open('streamlit_meeting_mcp.err','a'))\n",
    "    print('Streamlit started, pid=', st_proc.pid)\n",
    "    (Path('streamlit_meeting_mcp.pid')).write_text(str(st_proc.pid))\n",
    "except Exception as e:\n",
    "    print('Failed to start Streamlit:', e)\n",
    "time.sleep(3)\n",
    "# Kill existing tunnels to avoid duplicates\n",
    "try:\n",
    "    ngrok.kill()\n",
    "except Exception:\n",
    "    pass\n",
    "print('Opening ngrok tunnel to backend (8000) ...')\n",
    "backend_tunnel = ngrok.connect(8000, bind_tls=True)\n",
    "backend_url = backend_tunnel.public_url\n",
    "print('Backend public URL:', backend_url)\n",
    "os.environ['ORCHESTRATOR_BASE'] = backend_url\n",
    "os.environ['ORCHESTRATOR_URL'] = backend_url + '/mcp/orchestrate'\n",
    "time.sleep(1)\n",
    "print('Opening ngrok tunnel to Streamlit UI (8501) ...')\n",
    "ui_tunnel = ngrok.connect(8501, bind_tls=True)\n",
    "ui_url = ui_tunnel.public_url\n",
    "print('Streamlit public URL:', ui_url)\n",
    "print('Set ORCHESTRATOR_URL in your Streamlit client or use the UI URL above to access the app.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke test the orchestrator endpoint to ensure the backend responds.\n",
    "import requests, json, os\n",
    "backend = os.environ.get('ORCHESTRATOR_BASE') or 'http://127.0.0.1:8000'\n",
    "test_url = backend + '/mcp/orchestrate'\n",
    "payload = {'message':'ping','params':{}}\n",
    "try:\n",
    "    r = requests.post(test_url, json=payload, timeout=15)\n",
    "    print('Status code:', r.status_code)\n",
    "    try:\n",
    "        print('Response:', json.dumps(r.json(), indent=2))\n",
    "    except Exception:\n",
    "        print('Non-JSON response:', r.text[:1000])\n",
    "except Exception as e:\n",
    "    print('Failed to call orchestrator endpoint:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7143a",
   "metadata": {},
   "source": [
    "## Troubleshooting & next steps\n",
    "- If endpoints fail, check `uvicorn_meeting_mcp.log` and `streamlit_meeting_mcp.log` for errors.\n",
    "- To stop background services, run `ngrok.kill()` and kill PIDs recorded in `uvicorn_meeting_mcp.pid` and `streamlit_meeting_mcp.pid`.\n",
    "- If model loading fails, verify `BART_MODEL_PATH` and `MISTRAL_MODEL_PATH` point to valid local folders containing model files (config.json, pytorch_model.bin or similar)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
